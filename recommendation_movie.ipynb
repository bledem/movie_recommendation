{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cc5e08",
   "metadata": {},
   "source": [
    "# Movie recommendation system\n",
    "Explore different models for semantic text matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a0a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ccc88",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "Data is already prepared in folder ``data`` of this repository. Source: https://www.kaggle.com/rounakbanik/the-movies-dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f40f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/10972/Documents/NLP_PJ/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            sentence  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH = 'data/movies_metadata.csv' \n",
    "\n",
    "df = pd.read_csv(DATAPATH)\n",
    "df = df[~df.overview.isna()]\n",
    "df.rename(columns={'overview':'sentence'}, inplace=True)\n",
    "print(len(df))\n",
    "df = df.iloc[:20000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe41ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning sentences...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 4\n",
    "MAX_WORDS = 200\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Lemmatize, tokenize, crop and remove stop words.\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w for w in word_tokenize(sentence)]\n",
    "    token = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens    \n",
    "\n",
    "\n",
    "def clean_sentences(df):\n",
    "    \"\"\"\n",
    "    Remove irrelavant characters (in new column clean_sentence).\n",
    "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
    "    \"\"\"\n",
    "    print('Cleaning sentences...')\n",
    "    df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
    "    df['tok_lem_sentence'] = df['clean_sentence'].apply(\n",
    "        lambda x: tokenizer(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True))\n",
    "    return df\n",
    "    \n",
    "df = clean_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed392d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>tok_lem_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>led by woody  andy  toys live happily in his r...</td>\n",
       "      <td>[led, by, woody, andy, toy, live, happily, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>when siblings judy and peter discover an encha...</td>\n",
       "      <td>[when, sibling, judy, and, peter, discover, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>a family wedding reignites the ancient feud be...</td>\n",
       "      <td>[a, family, wedding, reignites, the, ancient, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>cheated on  mistreated and stepped on  the wom...</td>\n",
       "      <td>[cheated, on, mistreated, and, stepped, on, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>just when george banks has recovered from his ...</td>\n",
       "      <td>[just, when, george, bank, ha, recovered, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20131</th>\n",
       "      <td>After a lifetime of hiding, Chely Wright becom...</td>\n",
       "      <td>after a lifetime of hiding  chely wright becom...</td>\n",
       "      <td>[after, a, lifetime, of, hiding, chely, wright...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20132</th>\n",
       "      <td>In 1989, five black and Latino teenagers from ...</td>\n",
       "      <td>in 1989  five black and latino teenagers from ...</td>\n",
       "      <td>[in, 1989, five, black, and, latino, teenager,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20133</th>\n",
       "      <td>Arkin escapes with his life from the vicious g...</td>\n",
       "      <td>arkin escapes with his life from the vicious g...</td>\n",
       "      <td>[arkin, escape, with, his, life, from, the, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20134</th>\n",
       "      <td>Remake of a hit film from 1990, \"The Cherry Or...</td>\n",
       "      <td>remake of a hit film from 1990   the cherry or...</td>\n",
       "      <td>[remake, of, a, hit, film, from, 1990, the, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>Chronicles the adventures of Franklin Delano R...</td>\n",
       "      <td>chronicles the adventures of franklin delano r...</td>\n",
       "      <td>[chronicle, the, adventure, of, franklin, dela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      Led by Woody, Andy's toys live happily in his ...   \n",
       "1      When siblings Judy and Peter discover an encha...   \n",
       "2      A family wedding reignites the ancient feud be...   \n",
       "3      Cheated on, mistreated and stepped on, the wom...   \n",
       "4      Just when George Banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "20131  After a lifetime of hiding, Chely Wright becom...   \n",
       "20132  In 1989, five black and Latino teenagers from ...   \n",
       "20133  Arkin escapes with his life from the vicious g...   \n",
       "20134  Remake of a hit film from 1990, \"The Cherry Or...   \n",
       "20135  Chronicles the adventures of Franklin Delano R...   \n",
       "\n",
       "                                          clean_sentence  \\\n",
       "0      led by woody  andy  toys live happily in his r...   \n",
       "1      when siblings judy and peter discover an encha...   \n",
       "2      a family wedding reignites the ancient feud be...   \n",
       "3      cheated on  mistreated and stepped on  the wom...   \n",
       "4      just when george banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "20131  after a lifetime of hiding  chely wright becom...   \n",
       "20132  in 1989  five black and latino teenagers from ...   \n",
       "20133  arkin escapes with his life from the vicious g...   \n",
       "20134  remake of a hit film from 1990   the cherry or...   \n",
       "20135  chronicles the adventures of franklin delano r...   \n",
       "\n",
       "                                        tok_lem_sentence  \n",
       "0      [led, by, woody, andy, toy, live, happily, in,...  \n",
       "1      [when, sibling, judy, and, peter, discover, an...  \n",
       "2      [a, family, wedding, reignites, the, ancient, ...  \n",
       "3      [cheated, on, mistreated, and, stepped, on, th...  \n",
       "4      [just, when, george, bank, ha, recovered, from...  \n",
       "...                                                  ...  \n",
       "20131  [after, a, lifetime, of, hiding, chely, wright...  \n",
       "20132  [in, 1989, five, black, and, latino, teenager,...  \n",
       "20133  [arkin, escape, with, his, life, from, the, vi...  \n",
       "20134  [remake, of, a, hit, film, from, 1990, the, ch...  \n",
       "20135  [chronicle, the, adventure, of, franklin, dela...  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[['sentence', 'clean_sentence', 'tok_lem_sentence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a87bbf",
   "metadata": {},
   "source": [
    "## Query sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7f75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sentence = 'a crime story with a beautiful woman' \n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55423f",
   "metadata": {},
   "source": [
    "## Util function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1112d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_indices(m, topk, mask=None):\n",
    "    \"\"\"\n",
    "    Use sum of the cosine distance over all tokens.\n",
    "    m (np.array): cos matrix of shape (nb_in_tokens, nb_dict_tokens)\n",
    "    topk (int): number of indices to return (from high to lowest in order)\n",
    "    \"\"\"\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \n",
    "    if mask is not None:\n",
    "        assert mask.shape == m.shape\n",
    "        mask = mask[index]\n",
    "    else:\n",
    "        mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:topk]  \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde677b",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaea497",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a046d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/10972/Documents/NLP_PJ/env/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 49931)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Adapt stop words\n",
    "token_stop = tokenizer(' '.join(STOPWORDS), lemmatize=False)\n",
    "\n",
    "# Fit TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer) \n",
    "tfidf_mat = vectorizer.fit_transform(df['sentence'].values) # -> (num_sentences, num_vocabulary)\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193b01e",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ad1f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a crime story with a beautiful woman'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae4e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 20000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>Innocent Blood</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]</td>\n",
       "      <td>A beautiful vampire turns a crime lord into a creature of the night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>Requiem pour un vampire</td>\n",
       "      <td>[{'id': 27, 'name': 'Horror'}]</td>\n",
       "      <td>A vampire lures beautiful young women to his castle in Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18224</th>\n",
       "      <td>Miss Bala</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]</td>\n",
       "      <td>The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "9003            Innocent Blood   \n",
       "10493  Requiem pour un vampire   \n",
       "18224                Miss Bala   \n",
       "\n",
       "                                                                                                                          genres  \\\n",
       "9003   [{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]   \n",
       "10493                                                                                             [{'id': 27, 'name': 'Horror'}]   \n",
       "18224                                                                [{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]   \n",
       "\n",
       "                                                                                                                             sentence  \n",
       "9003                                                             A beautiful vampire turns a crime lord into a creature of the night.  \n",
       "10493                                                                  A vampire lures beautiful young women to his castle in Europe.  \n",
       "18224  The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_recommendations_tfidf(sentence, tfidf_mat):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the database sentences in order of highest cosine similarity relatively to each \n",
    "    token of the target sentence. \n",
    "    \"\"\"\n",
    "    # Embed the query sentence\n",
    "    tokens = [str(tok) for tok in tokenizer(sentence)]\n",
    "    vec = vectorizer.transform(tokens)\n",
    "    # Create list with similarity between query and dataset\n",
    "    mat = cosine_similarity(vec, tfidf_mat)\n",
    "    # Best cosine distance for each token independantly\n",
    "    print(mat.shape)\n",
    "    best_index = extract_best_indices(mat, topk=3)\n",
    "    return best_index\n",
    "\n",
    "\n",
    "best_index = get_recommendations_tfidf(query_sentence, tfidf_mat)\n",
    "\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85952a",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83cebd0",
   "metadata": {},
   "source": [
    "## Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca87b62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "#Load pre-trained model\n",
    "nlp = spacy.load(\"en_core_web_lg\") \n",
    "# Apply the model to the sentences\n",
    "df['spacy_sentence'] = df['sentence'].apply(lambda x: nlp(x)) \n",
    "# Retrieve the embedded vectors as a matrix \n",
    "embed_mat = df['spacy_sentence'].values\n",
    "embed_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f14262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/8cs69m1n759_xb3bt3fkk4982d1l4s/T/ipykernel_47525/1677401613.py:6: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  mat = np.array([query_embed.similarity(line) for line in embed_mat])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>Innocent Blood</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]</td>\n",
       "      <td>A beautiful vampire turns a crime lord into a creature of the night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>Requiem pour un vampire</td>\n",
       "      <td>[{'id': 27, 'name': 'Horror'}]</td>\n",
       "      <td>A vampire lures beautiful young women to his castle in Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18224</th>\n",
       "      <td>Miss Bala</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]</td>\n",
       "      <td>The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "9003            Innocent Blood   \n",
       "10493  Requiem pour un vampire   \n",
       "18224                Miss Bala   \n",
       "\n",
       "                                                                                                                          genres  \\\n",
       "9003   [{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]   \n",
       "10493                                                                                             [{'id': 27, 'name': 'Horror'}]   \n",
       "18224                                                                [{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]   \n",
       "\n",
       "                                                                                                                             sentence  \n",
       "9003                                                             A beautiful vampire turns a crime lord into a creature of the night.  \n",
       "10493                                                                  A vampire lures beautiful young women to his castle in Europe.  \n",
       "18224  The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_spacy(model, query_sentence, embed_mat, topk=5):\n",
    "    \"\"\"\n",
    "    Predict the topk sentences after applying spacy model.\n",
    "    \"\"\"\n",
    "    query_embed = model(query_sentence)\n",
    "    mat = np.array([query_embed.similarity(line) for line in embed_mat])\n",
    "    # keep if vector has a norm\n",
    "    mat_mask = np.array(\n",
    "        [True if line.vector_norm else False for line in embed_mat])\n",
    "    best_index = extract_best_indices(mat, topk=topk, mask=mat_mask)\n",
    "    return best_index\n",
    "\n",
    "# Predict\n",
    "predict_spacy(nlp, query_sentence, embed_mat)\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443ec88",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e687e9d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768d6747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/10972/Documents/NLP_PJ/env/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25186881, 33081030)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# Create model\n",
    "word2vec_model = Word2Vec(min_count=0, workers = 8, vector_size=300) \n",
    "# Prepare vocab\n",
    "word2vec_model.build_vocab(df.tok_lem_sentence.values)\n",
    "# Train\n",
    "word2vec_model.train(df.tok_lem_sentence.values, total_examples=word2vec_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535ee9f",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aab7f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>苏州河</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10769, 'name': 'Foreign'}, {'id': 10749, 'name': 'Romance'}]</td>\n",
       "      <td>A tragic love story set in contemporary Shanghai. The film stars Zhou Xun in a dual role as two different women and Jia Hongsheng as a man obsessed with finding a woman from his past.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>Printed Rainbow</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}]</td>\n",
       "      <td>A matchbox collection unites a lonely woman and her cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>A glowing orb terrorizes a young girl with a collection of stories of dark fantasy, eroticism and horror.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        original_title  \\\n",
       "9232               苏州河   \n",
       "14464  Printed Rainbow   \n",
       "602        Heavy Metal   \n",
       "\n",
       "                                                                                                  genres  \\\n",
       "9232   [{'id': 18, 'name': 'Drama'}, {'id': 10769, 'name': 'Foreign'}, {'id': 10749, 'name': 'Romance'}]   \n",
       "14464                                                                  [{'id': 16, 'name': 'Animation'}]   \n",
       "602                            [{'id': 16, 'name': 'Animation'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "\n",
       "                                                                                                                                                                                      sentence  \n",
       "9232   A tragic love story set in contemporary Shanghai. The film stars Zhou Xun in a dual role as two different women and Jia Hongsheng as a man obsessed with finding a woman from his past.  \n",
       "14464                                                                                                                                 A matchbox collection unites a lonely woman and her cat.  \n",
       "602                                                                                  A glowing orb terrorizes a young girl with a collection of stories of dark fantasy, eroticism and horror.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def is_word_in_model(word, model):\n",
    "    \"\"\"\n",
    "    Check on individual words ``word`` that it exists in ``model``.\n",
    "    \"\"\"\n",
    "    assert type(model).__name__ == 'KeyedVectors'\n",
    "    is_in_vocab = word in model.key_to_index.keys()\n",
    "    return is_in_vocab\n",
    "\n",
    "def predict_w2v(query_sentence, dataset, model, topk=3):\n",
    "    query_sentence = query_sentence.split()\n",
    "    in_vocab_list, best_index = [], [0]*topk\n",
    "    for w in query_sentence:\n",
    "        # remove unseen words from query sentence\n",
    "        if is_word_in_model(w, model.wv):\n",
    "            in_vocab_list.append(w)\n",
    "    # Retrieve the similarity between two words as a distance\n",
    "    if len(in_vocab_list) > 0:\n",
    "        sim_mat = np.zeros(len(dataset))  # TO DO\n",
    "        for i, data_sentence in enumerate(dataset):\n",
    "            if data_sentence:\n",
    "                sim_sentence = model.wv.n_similarity(\n",
    "                        in_vocab_list, data_sentence)\n",
    "            else:\n",
    "                sim_sentence = 0\n",
    "            sim_mat[i] = np.array(sim_sentence)\n",
    "        # Take the five highest norm\n",
    "        best_index = np.argsort(sim_mat)[::-1][:topk]\n",
    "    return best_index\n",
    "\n",
    "# Predict\n",
    "best_index = predict_w2v(query_sentence, df['tok_lem_sentence'].values, word2vec_model)    \n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48022680",
   "metadata": {},
   "source": [
    "# Transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9ce9b",
   "metadata": {},
   "source": [
    "## Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "072eba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cd4b15c49045229cf1fb90f0dfbd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165a5846e9354e8f96d5aed005046add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de64bb4beb54166af60bc80f0ef221d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff99b64c7d741749416a6d1fe574e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e93ac2a06f4d67b6678dab29e8055e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94092377bfd4c1ab53e69c50225f432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cc92c62ce446a68e52aa4832ff154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf4753005d24018a8ead9e5e4532d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d711a869ad407c87832a35447107d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d580f7693b540a4b9b18c7b340ddf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14f38836c48452fb1fba370664aa01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f206e5f12714557bc8bf4f0288bbd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/10972/Documents/NLP_PJ/env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(df.sentence.values, convert_to_tensor=True)\n",
    "query_embedding = model.encode(query_sentence, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c127179",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f2ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: a crime story with a beautiful woman\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "original_title                                                                                                                         Miss Bala\n",
       "genres                                                                               [{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]\n",
       "sentence          The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.\n",
       "Name: 18224, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "original_title                                                                                                                                                                                                                                                                                                                                 In the Cut\n",
       "genres                                                                                                                                                                                                                                                                                  [{'id': 9648, 'name': 'Mystery'}, {'id': 53, 'name': 'Thriller'}]\n",
       "sentence          Following the gruesome murder of a young woman in her neighborhood, a self-determined woman living in New York City--as if to test the limits of her own safety--propels herself into an impossibly risky sexual liaison. Soon she grows increasingly wary about the motives of every man with whom she has contact--and about her own.\n",
       "Name: 6736, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "original_title                                                                                    The World of Suzie Wong\n",
       "genres                                                    [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]\n",
       "sentence          Story of the love between a struggling American artist and a beautiful Chinese prostitute in Hong Kong.\n",
       "Name: 8018, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# We use cosine-similarity and torch.topk to find the highest 3 scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=3)\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query_sentence)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    score = score.cpu().data.numpy() \n",
    "    idx = idx.cpu().data.numpy()\n",
    "    display(df[['original_title', 'genres', 'sentence']].iloc[idx])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097d9ab",
   "metadata": {},
   "source": [
    "# BERT with hugging face\n",
    "We write a class to load the dataset, embed it in the object and use is to compute distance with embed query sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd5a92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "BERT_BATCH_SIZE = 4\n",
    "MODEL_NAME = 'sentence-transformers/paraphrase-MiniLM-L6-v2'\n",
    "\n",
    "class BertModel:\n",
    "    def __init__(self, model_name, device=-1, small_memory=True, batch_size=BERT_BATCH_SIZE):\n",
    "        self.model_name = model_name\n",
    "        self._set_device(device)\n",
    "        self.small_device = 'cpu' if small_memory else self.device\n",
    "        self.batch_size = batch_size\n",
    "        self.load_pretrained_model()\n",
    "\n",
    "    def _set_device(self, device):\n",
    "        if device == -1 or device == 'cpu':\n",
    "            self.device = 'cpu'\n",
    "        elif device == 'cuda' or device == 'gpu':\n",
    "            self.device = 'cuda'\n",
    "        elif isinstance(device, int) or isinstance(device, float):\n",
    "            self.device = 'cuda'\n",
    "        else:  # default\n",
    "            self.device = torch.device(\n",
    "                \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        device = -1 if self.device == 'cpu' else 0\n",
    "        self.pipeline = pipeline('feature-extraction',\n",
    "                                 model=self.model, tokenizer=self.tokenizer, device=device)\n",
    "\n",
    "    def embed(self, data):\n",
    "        \"\"\" Create the embedded matrice from original sentences \"\"\"\n",
    "        nb_batchs = 1 if (len(data) < self.batch_size) else len(\n",
    "            data) // self.batch_size\n",
    "        batchs = np.array_split(data, nb_batchs)\n",
    "        mean_pooled = []\n",
    "        for batch in tqdm(batchs, total=len(batchs), desc='Training...'):\n",
    "            mean_pooled.append(self.transform(batch))\n",
    "        mean_pooled_tensor = torch.tensor(\n",
    "            len(data), dtype=float).to(self.small_device)\n",
    "        mean_pooled = torch.cat(mean_pooled, out=mean_pooled_tensor)\n",
    "        self.embed_mat = mean_pooled\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(\n",
    "            -1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def transform(self, data):\n",
    "        if 'str' in data.__class__.__name__:\n",
    "            data = [data]\n",
    "        data = list(data)\n",
    "        token_dict = self.tokenizer(\n",
    "            data,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\")\n",
    "        token_dict = self.to(token_dict, self.device)\n",
    "        with torch.no_grad():\n",
    "            token_embed = self.model(**token_dict)\n",
    "        # each of the 512 token has a 768 or 384-d vector depends on model)\n",
    "        attention_mask = token_dict['attention_mask']\n",
    "        # average pooling of masked embeddings\n",
    "        mean_pooled = self.mean_pooling(\n",
    "            token_embed, attention_mask)\n",
    "        mean_pooled = mean_pooled.to(self.small_device)\n",
    "        return mean_pooled\n",
    "    \n",
    "    def to(self, data: dict, device: str):\n",
    "        \"\"\"Send all values to device by calling v.to(device)\"\"\"\n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        return data\n",
    "\n",
    "    def predict(self, in_sentence, topk=3):\n",
    "        input_vec = self.transform(in_sentence)\n",
    "        mat = cosine_similarity(input_vec, self.embed_mat)\n",
    "        # best cos sim for each token independantly\n",
    "        best_index = extract_best_indices(mat, topk=topk)\n",
    "        return best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d821c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a2bfaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████████████████████| 5000/5000 [10:33<00:00,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# CPU training\n",
    "bert_model = BertModel(model_name=MODEL_NAME, batch_size=BERT_BATCH_SIZE)\n",
    "bert_model.embed(df.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU training\n",
    "bert_model_gpu = BertModel(model_name=MODEL_NAME, batch_size=BERT_BATCH_SIZE, device='cuda')\n",
    "bert_model_gpu.transform(df.sentence.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afff360",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bff84df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim (1, 20000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14496</th>\n",
       "      <td>The Princess and the Frog</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 10751, 'name': 'Family'}, {'id': 16, 'name': 'Animation'}, {'id': 10402, 'name': 'Music'}]</td>\n",
       "      <td>A waitress, desperate to fulfill her dreams as a restaurant owner, is set on a journey to turn a frog prince back into a human being, but she has to do face the same problem after she kisses him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>WiseGirls</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 53, 'name': 'Thriller'}]</td>\n",
       "      <td>A new waitress working at an Italian restaurant in New York City finds herself entangled in a mob-run underworld of drug dealing and murder.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11700</th>\n",
       "      <td>Fauteuils d'orchestre</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]</td>\n",
       "      <td>A young woman arrives in Paris where she finds a job as a waitress in bar next on Avenue Montaigne that caters to the surrounding theaters and the wealthy inhabitants of the area. She will meet a pianist, a famous actress and a great art collector, and become acquainted with the \"luxurious\" world her grandmother has told her about since her childhood.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  original_title  \\\n",
       "14496  The Princess and the Frog   \n",
       "5873                   WiseGirls   \n",
       "11700      Fauteuils d'orchestre   \n",
       "\n",
       "                                                                                                                                     genres  \\\n",
       "14496  [{'id': 10749, 'name': 'Romance'}, {'id': 10751, 'name': 'Family'}, {'id': 16, 'name': 'Animation'}, {'id': 10402, 'name': 'Music'}]   \n",
       "5873              [{'id': 28, 'name': 'Action'}, {'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 53, 'name': 'Thriller'}]   \n",
       "11700                                         [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                sentence  \n",
       "14496                                                                                                                                                                A waitress, desperate to fulfill her dreams as a restaurant owner, is set on a journey to turn a frog prince back into a human being, but she has to do face the same problem after she kisses him.  \n",
       "5873                                                                                                                                                                                                                        A new waitress working at an Italian restaurant in New York City finds herself entangled in a mob-run underworld of drug dealing and murder.  \n",
       "11700  A young woman arrives in Paris where she finds a job as a waitress in bar next on Avenue Montaigne that caters to the surrounding theaters and the wealthy inhabitants of the area. She will meet a pianist, a famous actress and a great art collector, and become acquainted with the \"luxurious\" world her grandmother has told her about since her childhood.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_sentence = 'the story of a waitress'\n",
    "indices = bert_model_gpu.predict(query_sentence)\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[indices])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
